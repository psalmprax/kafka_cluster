apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: kafka-cluster
data:
  server.properties: |
    # Broker ID - This will typically be overridden by an init container or startup script
    # based on the pod's hostname (e.g., kafka-0 -> broker.id=0)
    # broker.id=

    # Log directories
    log.dirs=/var/lib/kafka/data

    # Zookeeper connection
    zookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty
    zookeeper.connect=zookeeper-svc.kafka-cluster.svc.cluster.local:2281 # Secure ZK port

    ############################# Socket Server Settings #############################
    # Listener Configuration
    # The KAFKA_ADVERTISED_LISTENERS environment variable will typically set this dynamically in the pod.
    # advertised.listeners=
    listeners=INTERNAL_SSL://0.0.0.0:9093
    listener.security.protocol.map=INTERNAL_SSL:SSL

    inter.broker.listener.name=INTERNAL_SSL
    # controller.listener.names=CONTROLLER # Remove for ZK mode
    # security.inter.broker.protocol=SSL # Already implied by inter.broker.listener.name mapping

    # SSL Configuration for Kafka Listeners
    ssl.keystore.location=/etc/kafka/secrets/kafka.server.keystore.jks # Corrected path
    ssl.keystore.password=__KAFKA_SERVER_KEYSTORE_PASSWORD__
    ssl.key.password=__KAFKA_SERVER_KEY_PASSWORD__
    ssl.truststore.location=/etc/kafka/secrets/kafka.server.truststore.jks # Corrected path
    ssl.truststore.password=__KAFKA_SERVER_TRUSTSTORE_PASSWORD__
    ssl.client.auth=required # Enforce mTLS from clients and for inter-broker
    ssl.endpoint.identification.algorithm=https # Recommended for hostname verification
    ssl.enabled.protocols=TLSv1.2,TLSv1.3
    ssl.protocol=TLSv1.3 # Preferred protocol
    ssl.cipher.suites=TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_DHE_RSA_WITH_AES_256_GCM_SHA384,TLS_DHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256

    # SSL Configuration for Kafka Client to Zookeeper
    zookeeper.ssl.client.enable=true
    zookeeper.ssl.keystore.location=/etc/kafka/secrets/kafka.zkclient.keystore.jks # Corrected path
    zookeeper.ssl.keystore.password=__KAFKA_ZKCLIENT_KEYSTORE_PASSWORD__ # This is set by the KAFKA_ZOOKEEPER_SSL_KEYSTORE_PASSWORD env var
    zookeeper.ssl.truststore.location=/etc/kafka/secrets/kafka.zkclient.truststore.jks # Corrected path
    zookeeper.ssl.truststore.password=__KAFKA_ZKCLIENT_TRUSTSTORE_PASSWORD__ # This is set by the KAFKA_ZOOKEEPER_SSL_TRUSTSTORE_PASSWORD env var
    zookeeper.ssl.protocol=TLSv1.2 # Explicitly set protocol for ZK client
    zookeeper.ssl.endpoint.identification.algorithm=HTTPS # Hostname verification for ZK

    # KRaft mode settings (if applicable, otherwise remove or comment out)
    # process.roles=broker,controller # or just 'broker' if dedicated controllers
    # node.id= # Will be same as broker.id
    # controller.quorum.voters=0@kafka-0.kafka-headless.kafka-cluster.svc.cluster.local:9094,1@kafka-1.kafka-headless.kafka-cluster.svc.cluster.local:9094,2@kafka-2.kafka-headless.kafka-cluster.svc.cluster.local:9094

    ############################# Log Basics #############################
    num.partitions=1
    default.replication.factor=3
    min.insync.replicas=2
    offsets.topic.replication.factor=3
    transaction.state.log.replication.factor=3
    transaction.state.log.min.isr=2

    # Set the default cleanup policy for auto-created topics.
    # Schema Registry requires its internal _schemas topic to have a 'compact' policy for log compaction.
    log.cleanup.policy=compact
    

    ############################# Internal Topic Settings  #############################
    # auto.create.topics.enable=true # Consider setting to false in production

    ############################# Other Settings #############################
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    group.initial.rebalance.delay.ms=0
  # You can add log4j.properties here as well if needed
  # log4j.properties: |
  #   kafka.root.logger=INFO, stdout
  #   ...
